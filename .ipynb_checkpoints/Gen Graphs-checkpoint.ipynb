{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.4'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "nx.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this code is used to generate graphs\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid \n",
    "### train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_grid(grid_start,grid_end):\n",
    "    adjs = []\n",
    "    n_nodes = []\n",
    "    for i in range(grid_start, grid_end):\n",
    "        for j in range(grid_start, grid_end):\n",
    "            G = nx.grid_2d_graph(i, j)\n",
    "            adj = nx.adjacency_matrix(G).toarray()\n",
    "            adjs.append(adj)\n",
    "            n_nodes.append(len(G.nodes()))\n",
    "    n_max = (grid_end - 1) * (grid_end - 1)\n",
    "    #print(len(adjs),n_max,np.max(n_nodes),np.min(n_nodes))\n",
    "    return np.array(adjs, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_191975/331194899.py:7: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  adj = nx.adjacency_matrix(G).toarray()\n",
      "/tmp/ipykernel_191975/331194899.py:7: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  adj = nx.adjacency_matrix(G).toarray()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "grid_start = 10\n",
    "grid_end = 20\n",
    "adjs = build_grid(grid_start,grid_end)\n",
    "random.seed(42)\n",
    "graphs_len = len(adjs)\n",
    "idxs = list(range(graphs_len))\n",
    "random.shuffle(idxs)\n",
    "test_idxs = idxs[int(0.8 * graphs_len):]\n",
    "val_idxs = idxs[0:int(0.2*graphs_len)]\n",
    "train_idxs = idxs[int(0.2*graphs_len):int(0.8*graphs_len)]\n",
    "\n",
    "test = adjs[test_idxs]\n",
    "train = adjs[train_idxs]\n",
    "val = adjs[val_idxs]\n",
    "\n",
    "np.save(\"dataset/grid/grid_train_val_test.npy\",np.array([train,val,test], dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_grid(grid_start,grid_end,ink):\n",
    "    adjs = []\n",
    "    n_nodes = []\n",
    "    for i in range(grid_start, grid_end,ink):\n",
    "        for j in range(grid_start, grid_end,ink):\n",
    "            G = nx.grid_2d_graph(i, j)\n",
    "            adj = nx.adjacency_matrix(G).toarray()\n",
    "            adjs.append(adj)\n",
    "            n_nodes.append(len(G.nodes()))\n",
    "    n_max = (grid_end - 1) * (grid_end - 1)\n",
    "    #print(len(adjs),n_max,np.max(n_nodes),np.min(n_nodes))\n",
    "    adjs = np.array(adjs, dtype=object)\n",
    "    np.random.shuffle(adjs)\n",
    "    return adjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid start 55 grid end 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_191975/1680752995.py:7: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  adj = nx.adjacency_matrix(G).toarray()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "grid_start = 10\n",
    "grid_end = 20\n",
    "m = 15\n",
    "#for increm in [1.1,1.25,1.5,2.0,4.0]:#,8.0]:\n",
    "for increm in [4.0]:#,8.0]:\n",
    "    new_m = int(m*increm)\n",
    "    nodes_min = new_m-5\n",
    "    nodes_max = new_m+5\n",
    "    print(\"grid start\",nodes_min,\"grid end\",nodes_max)\n",
    "    \n",
    "\n",
    "    adjs = build_grid(nodes_min,nodes_max,1)\n",
    "    adjs = adjs[0:100]\n",
    "    print(len(adjs))\n",
    "    np.save(\"dataset/grid/grid_large_\"+str(increm)+\".npy\",adjs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid\n",
      "incremento  1.5 NUMERO RANDOM DA 15 a 30\n",
      "incremento  2.0 NUMERO RANDOM DA 20 a 40\n",
      "incremento  4.0 NUMERO RANDOM DA 40 a 80\n"
     ]
    }
   ],
   "source": [
    "grid_start = 10\n",
    "grid_end = 20\n",
    "print(\"grid\")\n",
    "for increm in [1.5,2.0,4.0]:#,8.0]:\n",
    "    nodes_min = int(grid_start*increm)\n",
    "    nodes_max = int(grid_end*increm)\n",
    "    print(\"incremento \",increm, \"NUMERO RANDOM DA\",nodes_min,\"a\",nodes_max)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planar\n",
    "## train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import Delaunay\n",
    "def build_planar(n_graphs,n_nodes_in):\n",
    "    adjs = []\n",
    "    n_nodes = []\n",
    "    for i in range(n_graphs):\n",
    "        # Generate planar graphs using Delauney traingulation\n",
    "        points = np.random.rand(n_nodes_in,2)\n",
    "        tri = Delaunay(points)\n",
    "        adj = np.zeros([n_nodes_in,n_nodes_in])\n",
    "\n",
    "        for t in tri.simplices:\n",
    "            adj[t[0], t[1]] = 1\n",
    "            adj[t[1], t[2]] = 1\n",
    "            adj[t[2], t[0]] = 1\n",
    "            adj[t[1], t[0]] = 1\n",
    "            adj[t[2], t[1]] = 1\n",
    "            adj[t[0], t[2]] = 1\n",
    "\n",
    "        G = nx.from_numpy_matrix(adj)\n",
    "\n",
    "        adjs.append(adj)\n",
    "        n_nodes.append(len(G.nodes()))\n",
    "    return np.array(adjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_graphs = 200\n",
    "n_nodes_in = 64\n",
    "\n",
    "adjs = build_planar(n_graphs,n_nodes_in)\n",
    "\n",
    "random.seed(42)\n",
    "graphs_len = len(adjs)\n",
    "idxs = list(range(graphs_len))\n",
    "random.shuffle(idxs)\n",
    "test_idxs = idxs[int(0.8 * graphs_len):]\n",
    "val_idxs = idxs[0:int(0.2*graphs_len)]\n",
    "train_idxs = idxs[int(0.2*graphs_len):int(0.8*graphs_len)]\n",
    "\n",
    "test = adjs[test_idxs]\n",
    "train = adjs[train_idxs]\n",
    "val = adjs[val_idxs]\n",
    "\n",
    "np.save(\"dataset/planar/planar_train_val_test.npy\",np.array([train,val,test], dtype=object))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## planar_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 X 1.1 = 70\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'build_planar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m n_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(orig_size\u001b[38;5;241m*\u001b[39mincrem)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(orig_size,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,increm,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m,n_nodes)\n\u001b[0;32m----> 6\u001b[0m adjs \u001b[38;5;241m=\u001b[39m build_planar(n_graphs,n_nodes)\n\u001b[1;32m      8\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset/planar/planar_large_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(increm)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m,adjs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'build_planar' is not defined"
     ]
    }
   ],
   "source": [
    "n_graphs = 200\n",
    "n_nodes_in = 64\n",
    "for increm in [1.1,1.25,1.5,2.0,4.0,8.0]:\n",
    "    n_nodes = int(orig_size*increm)\n",
    "    print(orig_size,\"X\",increm,\"=\",n_nodes)\n",
    "    adjs = build_planar(n_graphs,n_nodes)\n",
    "    \n",
    "    np.save(\"dataset/planar/planar_large_\"+str(increm)+\".npy\",adjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "planar\n",
      "incremento  1.5 NUMERO max nodi 96\n",
      "incremento  2.0 NUMERO max nodi 128\n",
      "incremento  4.0 NUMERO max nodi 256\n",
      "incremento  8.0 NUMERO max nodi 512\n"
     ]
    }
   ],
   "source": [
    "orig_size = 64\n",
    "print(\"planar\")\n",
    "for increm in [1.5,2.0,4.0,8.0]:\n",
    "    n_nodes = int(orig_size*increm)\n",
    "    print(\"incremento \",increm, \"NUMERO max nodi\",n_nodes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ego"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjs = np.load(\"dataset/ego_small.npy\")\n",
    "\n",
    "random.seed(42)\n",
    "graphs_len = len(adjs)\n",
    "idxs = list(range(graphs_len))\n",
    "random.shuffle(idxs)\n",
    "test_idxs = idxs[int(0.8 * graphs_len):]\n",
    "val_idxs = idxs[0:int(0.2*graphs_len)]\n",
    "train_idxs = idxs[int(0.2*graphs_len):int(0.8*graphs_len)]\n",
    "\n",
    "test = adjs[test_idxs]\n",
    "train = adjs[train_idxs]\n",
    "val = adjs[val_idxs]\n",
    "\n",
    "np.save(\"dataset/ego/ego_train_val_test.npy\",np.array([train,val,test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sbm(n_graphs,max_comm_size,min_comm_size,min_n_com,max_n_com):\n",
    "    adjs = []\n",
    "    for seed in range(n_graphs):\n",
    "        n_comunities = np.random.randint(min_n_com, max_n_com)\n",
    "        comunity_sizes = np.random.randint(min_comm_size, max_comm_size, size=n_comunities)\n",
    "        probs = np.ones([n_comunities, n_comunities]) * 0.005\n",
    "        probs[np.arange(n_comunities), np.arange(n_comunities)] = 0.3\n",
    "\n",
    "        G = nx.stochastic_block_model(comunity_sizes, probs, seed=seed)\n",
    "        adj = nx.adjacency_matrix(G).A\n",
    "        adjs.append(adj)\n",
    "    return np.array(adjs, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits\n",
    "n_graphs =  200\n",
    "max_comm_size = 40\n",
    "min_comm_size = 20\n",
    "min_n_com = 2\n",
    "max_n_com = 5\n",
    "\n",
    "adjs = build_sbm(n_graphs,max_comm_size,min_comm_size,min_n_com,max_n_com)\n",
    "\n",
    "random.seed(42)\n",
    "graphs_len = len(adjs)\n",
    "idxs = list(range(graphs_len))\n",
    "random.shuffle(idxs)\n",
    "test_idxs = idxs[int(0.8 * graphs_len):]\n",
    "val_idxs = idxs[0:int(0.2*graphs_len)]\n",
    "train_idxs = idxs[int(0.2*graphs_len):int(0.8*graphs_len)]\n",
    "\n",
    "test = adjs[test_idxs]\n",
    "train = adjs[train_idxs]\n",
    "val = adjs[val_idxs]\n",
    "\n",
    "np.save(\"dataset/sbm/sbm_train_val_test.npy\",np.array([train,val,test], dtype=object))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SBM large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_graphs = 200\n",
    "orig_size_max = 40\n",
    "orig_size_min = 20\n",
    "min_n_com = 2\n",
    "max_n_com = 5\n",
    "\n",
    "for increm in [1.1,1.25,1.5,2.0,4.0,8.0]:\n",
    "    nodes_min = int(orig_size_min*increm)\n",
    "    nodes_max = int(orig_size_max*increm)\n",
    "    print(\"MIN\",nodes_min,\"MAX\",nodes_max,\"\\tnb comm:\",min_n_com,\"-\",max_n_com)\n",
    "    \n",
    "    adjs = build_sbm(n_graphs,nodes_max,nodes_min,min_n_com,max_n_com)\n",
    "    np.save(\"dataset/sbm/sbm_large_\"+str(increm)+\".npy\",adjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for increm in [1.1,1.25,1.5,2.0,4.0,8.0]:\n",
    "    A = np.load(\"dataset/sbm/sbm_large_\"+str(increm)+\".npy\",allow_pickle=True)\n",
    "    #graphs = [nx.from_numpy_array(x) for x in A]\n",
    "    dist = [len(x) for x in A]\n",
    "    res.append(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,3))\n",
    "# no 1.1 e 1.25\n",
    "incremenst = [1.1,1.25,1.5,2.0,4.0,8.0]\n",
    "c = 0\n",
    "for i in res:\n",
    "    plt.hist(i,density=True,alpha=0.8,label=str(incremenst[c]))\n",
    "    c =  c + 1\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incremento  1.5 NUMERO random da 30 a 60\n",
      "incremento  2.0 NUMERO random da 40 a 80\n",
      "incremento  4.0 NUMERO random da 80 a 160\n",
      "incremento  8.0 NUMERO random da 160 a 320\n"
     ]
    }
   ],
   "source": [
    "n_graphs =  200\n",
    "orig_size_max = 40\n",
    "orig_size_min = 20\n",
    "min_n_com = 2\n",
    "max_n_com = 5\n",
    "\n",
    "for increm in [1.5,2.0,4.0,8.0]:\n",
    "    nodes_min = int(orig_size_min*increm)\n",
    "    nodes_max = int(orig_size_max*increm)\n",
    "    print(\"incremento \",increm, \"NUMERO random da\",nodes_min,\"a\",nodes_max)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-20"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20-40\n",
    "\n",
    "\n",
    "min 40\n",
    "max 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "30*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(np.random.randint(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

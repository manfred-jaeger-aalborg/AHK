{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5107db15",
   "metadata": {},
   "source": [
    "# Quick start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb5ac916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azzolin/miniconda3/envs/digress2_clone/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import math\n",
    "import time\n",
    "import pickle as pkl\n",
    "import scipy\n",
    "import sys\n",
    "sys.path.insert(0, '/home/azzolin/AHK')\n",
    "import utils\n",
    "\n",
    "from ahk import AHK_graphon\n",
    "from ahk_generators import data_colors, ahk_sbm, sample_data\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df992cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define an AHK model representing a stochastic block model:\n",
    "\n",
    "colprobs = np.array([0.2, 0.3, 0.5]) #np.array([1])\n",
    "edgeprobs = np.array([[0.6,0.1,0.1],[0.1,0.9,0.1],[0.1,0.1,0.8]])\n",
    "\n",
    "# sbm = ahk_sbm(colprobs, edgeprobs, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73a965ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sample random graphs from the model\n",
    "\n",
    "# minnodes = 8\n",
    "# maxnodes = 30\n",
    "# samplesize = 5\n",
    "\n",
    "# sample = sample_data(sbm,samplesize,minnodes,maxnodes)\n",
    "\n",
    "### these sampled graphs are now instances of utils.World\n",
    "### They are converted to networkx graphs for plotting\n",
    "\n",
    "#\n",
    "#for g in sample:\n",
    "#    gnx=g.to_nx()\n",
    "#    nodecols=(list(gnx.nodes()[j]['features'] for j in gnx.nodes()))\n",
    "#    nx.draw_networkx(gnx,node_color=nodecols,cmap='Set3')\n",
    "#    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8a96eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sample[0]\n",
    "# g = g.to_nx()\n",
    "# g.nodes(data=True)\n",
    "# g.edges(data=True)\n",
    "# g = nx.Graph(g)\n",
    "# g.edges()[(0,2)][\"bici\"] = 2\n",
    "# g.edges(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c624ae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for g in range(5):\n",
    "#     g = nx.stochastic_block_model([5, 5, 5], edgeprobs)\n",
    "#     nx.draw_networkx(g, cmap='Set3')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715c306c",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e025720",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_GRAPHS = 100\n",
    "\n",
    "traindata = []\n",
    "for _ in range(NUM_GRAPHS):\n",
    "    g = nx.stochastic_block_model([5,5,5], edgeprobs)\n",
    "    # nx.set_node_attributes(g, 0, \"features\") # DO NOT ADD NODE ATTRIBS\n",
    "    g = utils.nx_to_world(g)\n",
    "    traindata.append(g)\n",
    "g.sig.unaries\n",
    "\n",
    "\n",
    "# Initializing a model. This requires to define the histogram partitioning of the [0,1] interval\n",
    "# that the model uses\n",
    "# The first argument in the constructor is the signature of the graphs we are dealing with, i.e.\n",
    "# a specification of the attributes and relations\n",
    "\n",
    "\n",
    "binbounds = utils.uni_bins(3)\n",
    "model_learned = AHK_graphon(traindata[0].sig, binbounds)\n",
    "\n",
    "# Defining settings:\n",
    "settings={}\n",
    "settings['num_pi_b']=50\n",
    "settings['batchsize']=10\n",
    "settings['soft']=0.01\n",
    "settings['numepochs']=30\n",
    "settings['learn_bins']=False\n",
    "settings['early_stop']=5\n",
    "settings['with_trace']=False\n",
    "\n",
    "#Adam params:\n",
    "settings['ad_alpha']=0.01\n",
    "settings['ad_beta1']=0.99\n",
    "settings['ad_beta2']=0.9\n",
    "settings['ad_epsilon']=10e-8\n",
    "\n",
    "settings['method']=\"adam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dcb9c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Random initialization and learning\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model_learned\u001b[39m.\u001b[39mrand_init()\n\u001b[0;32m----> 3\u001b[0m best, loglik, trace \u001b[39m=\u001b[39m model_learned\u001b[39m.\u001b[39;49mlearn(settings, traindata)\n",
      "File \u001b[0;32m~/AHK/ahk.py:1064\u001b[0m, in \u001b[0;36mAHK_graphon.learn\u001b[0;34m(self, settings, data, **kwargs)\u001b[0m\n\u001b[1;32m   1061\u001b[0m epochll\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m   1062\u001b[0m \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(numbatches)):          \n\u001b[0;32m-> 1064\u001b[0m     gf1,gf2,gbb,llbatch\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimate_grad_batch(nextbatch,learn_bins,num_pi_b)\n\u001b[1;32m   1065\u001b[0m     \u001b[39m#print(\"grad f1: \", gf1[0],'\\n')\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m     \u001b[39m#print(\"grad f2 (b2,b2): \", gf2[1,1,0,0],gf2[1,1,0,1],'\\n')\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m     epochll\u001b[39m+\u001b[39m\u001b[39m=\u001b[39mllbatch\n",
      "File \u001b[0;32m~/AHK/ahk.py:752\u001b[0m, in \u001b[0;36mAHK_graphon.estimate_grad_batch\u001b[0;34m(self, batch, learn_bins, num_pi_b)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mestimate_grad_batch\u001b[39m(\u001b[39mself\u001b[39m,batch,learn_bins,num_pi_b\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m--> 752\u001b[0m     gg1,gg2,ggv,p\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimate_grad(batch[\u001b[39m0\u001b[39;49m],learn_bins,num_pi_b)\n\u001b[1;32m    753\u001b[0m     \u001b[39m#print(\"batch first p: \", p)\u001b[39;00m\n\u001b[1;32m    754\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39mlen\u001b[39m(batch)):\n",
      "File \u001b[0;32m~/AHK/ahk.py:725\u001b[0m, in \u001b[0;36mAHK_graphon.estimate_grad\u001b[0;34m(self, w, learn_bins, num_pi_b)\u001b[0m\n\u001b[1;32m    721\u001b[0m importanceweight\u001b[39m=\u001b[39mv\u001b[39m/\u001b[39m(pi_b[i][\u001b[39m2\u001b[39m])\n\u001b[1;32m    724\u001b[0m g1\u001b[39m=\u001b[39m\u001b[39mlist\u001b[39m(g1[att] \u001b[39m+\u001b[39m g1n[att]\u001b[39m*\u001b[39mimportanceweight  \u001b[39mfor\u001b[39;00m att \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattrange)\n\u001b[0;32m--> 725\u001b[0m trace\u001b[39m.\u001b[39mappend(g1[\u001b[39m0\u001b[39;49m]\u001b[39m/\u001b[39m(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m    727\u001b[0m \u001b[39m#print(\"gradient b1,b1: \", (g2n)[1,1,0,0], (g2n)[1,1,0,1])            \u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[39m#print(\"weighted g2 gradient b1,b1: \", (g2n*importanceweight)[1,1,0,0], (g2n*importanceweight)[1,1,0,1])\u001b[39;00m\n\u001b[1;32m    730\u001b[0m g2\u001b[39m+\u001b[39m\u001b[39m=\u001b[39mg2n\u001b[39m*\u001b[39mimportanceweight\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Random initialization and learning\n",
    "model_learned.rand_init()\n",
    "best, loglik, trace = model_learned.learn(settings, traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256e5c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample_data(model_learned, 5, 5, 30)\n",
    "\n",
    "for g in sample:\n",
    "   gnx = g.to_nx()\n",
    "   nodecols = (list(gnx.nodes()[j]['features'] for j in gnx.nodes()))\n",
    "   nx.draw_networkx(gnx, node_color=nodecols, cmap='Set3')\n",
    "   plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
